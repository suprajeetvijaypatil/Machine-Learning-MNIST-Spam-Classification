{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5abc1654",
   "metadata": {},
   "source": [
    "\n",
    "# Task 3: SMS Spam Detection — N-gram and Random Forest Models\n",
    "\n",
    "This notebook implements SMS spam detection using:\n",
    "1. **Pure N-gram Models (Unigram, Bigram, Trigram)** — probability-based (no ML).\n",
    "2. **Random Forest Algorithm** — with TF-IDF features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235eef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "from collections import Counter\n",
    "from math import log\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"SMSSpamCollection\", sep=\"\\t\", names=[\"label\", \"message\"])\n",
    "\n",
    "# Preprocess messages\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tokens = text.split()\n",
    "    return tokens\n",
    "\n",
    "df[\"tokens\"] = df[\"message\"].apply(preprocess)\n",
    "\n",
    "# Split into train and test\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df[\"label\"], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82764ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_ngram_model(n=1):\n",
    "    # Get n-grams for spam and ham\n",
    "    def get_ngrams(tokens_list, n):\n",
    "        ngrams = []\n",
    "        for tokens in tokens_list:\n",
    "            ngrams += [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "        return ngrams\n",
    "\n",
    "    spam_tokens = train_df[train_df[\"label\"] == \"spam\"][\"tokens\"].tolist()\n",
    "    ham_tokens = train_df[train_df[\"label\"] == \"ham\"][\"tokens\"].tolist()\n",
    "\n",
    "    spam_ngrams = get_ngrams(spam_tokens, n)\n",
    "    ham_ngrams = get_ngrams(ham_tokens, n)\n",
    "\n",
    "    spam_counts = Counter(spam_ngrams)\n",
    "    ham_counts = Counter(ham_ngrams)\n",
    "\n",
    "    V = len(set(list(spam_counts.keys()) + list(ham_counts.keys())))\n",
    "    total_spam = sum(spam_counts.values())\n",
    "    total_ham = sum(ham_counts.values())\n",
    "\n",
    "    def message_log_prob(tokens, label):\n",
    "        ngrams = [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "        log_prob = 0.0\n",
    "        for ng in ngrams:\n",
    "            if label == \"spam\":\n",
    "                count = spam_counts.get(ng, 0)\n",
    "                prob = (count + 1) / (total_spam + V)\n",
    "            else:\n",
    "                count = ham_counts.get(ng, 0)\n",
    "                prob = (count + 1) / (total_ham + V)\n",
    "            log_prob += log(prob)\n",
    "        return log_prob\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        tokens = row[\"tokens\"]\n",
    "        spam_score = message_log_prob(tokens, \"spam\")\n",
    "        ham_score = message_log_prob(tokens, \"ham\")\n",
    "        predicted = \"spam\" if spam_score > ham_score else \"ham\"\n",
    "\n",
    "        y_true.append(row[\"label\"])\n",
    "        y_pred.append(predicted)\n",
    "\n",
    "    accuracy = sum(1 for a, b in zip(y_true, y_pred) if a == b) / len(y_true)\n",
    "    print(f\"\\n✅ Accuracy of {n}-gram model: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Unigram Model ----\n",
    "train_ngram_model(n=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Bigram Model ----\n",
    "train_ngram_model(n=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9be2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Trigram Model ----\n",
    "train_ngram_model(n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9e1fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---- Random Forest Model (TF-IDF) ----\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_df[\"message\"])\n",
    "X_test = vectorizer.transform(test_df[\"message\"])\n",
    "\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "clf.fit(X_train, train_df[\"label\"])\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "print(\"\\n✅ Random Forest Model Results:\")\n",
    "print(classification_report(test_df[\"label\"], pred))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
